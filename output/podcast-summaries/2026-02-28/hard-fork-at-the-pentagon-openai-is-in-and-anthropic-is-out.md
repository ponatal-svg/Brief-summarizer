# At the Pentagon, OpenAI is In and Anthropic Is Out

**Show:** Hard Fork | **Category:** AI | **Duration:** 33m 8s | **Published:** 2026-03-01 | **Language:** en

**Source:** [https://www.nytimes.com/column/hard-fork](https://www.nytimes.com/column/hard-fork)

---

## The Hook
The AI industry experienced an unprecedented 48 hours as the Pentagon first moved to label leading AI company Anthropic a "supply chain risk" for refusing to compromise on certain ethical safeguards, only for rival OpenAI to announce a deal with the government with seemingly identical stipulations. This conflict exposes a high-stakes battle over who controls powerful AI technology and how it will be used.

## Key Findings
*   **Anthropic's "Red Lines" and Pentagon's Response:** Anthropic CEO Dario Amodei stated the company would not compromise on the use of its AI models for "mass domestic surveillance and fully autonomous weapons," declaring that the company could "not in good conscience accede to their request." Following a statement from President Trump criticizing Anthropic as a "radical left woke company," Defense Secretary Pete Hegseth officially directed the department to designate Anthropic a "supply chain risk." This punitive measure requires federal agencies to immediately cease all commercial activity with Anthropic, forcing a six-month phase-out period.
*   **OpenAI's Parallel Deal:** While Anthropic faced severe government action, OpenAI CEO Sam Altman announced that his company had reached an agreement with the Pentagon to deploy its models in classified networks. Altman claimed this deal incorporated principles preventing their models from being used for domestic mass surveillance and autonomous weapons systems, seemingly mirroring Anthropic's stated "red lines." However, the exact language of these contracts has not been made public, leading to questions about the actual terms.
*   **The Nuance of "All Lawful Use":** The conflict highlights the legal and practical interpretations of AI use. The Pentagon pressed for an "all lawful use" standard, which, according to the hosts, allows for actions functionally equivalent to domestic surveillance (e.g., buying data from brokers) despite not being classified as illegal surveillance under current laws. Anthropic reportedly believed that the "legalese" in proposed deals would have rendered their safeguards ineffective, allowing the Pentagon to do "exactly what they're doing with the social media accounts of would-be immigrants."
*   **Political Vendetta and Regulatory Capture:** The hosts explore two main theories: either the Pentagon's actions against Anthropic were a "purely political vendetta" due to ideological differences and personal animosity from officials like Undersecretary Emil Michael, or OpenAI leveraged the situation for "regulatory capture." This latter theory suggests OpenAI positioned itself as the preferred government partner by appearing to concede to government terms, using "vibes, charm, possibly some better political instincts" to gain an advantage over its biggest rival.
*   **Employee Activism and Moral Implications:** Employees from various AI companies, including OpenAI, Google DeepMind, and Anthropic, signed an open letter expressing solidarity with Anthropic's stance against building tools for mass domestic surveillance and autonomous killing. This collective voice is considered "very meaningful" by the hosts, who note the profound moral and ethical consequences of AI technology. Dario Amodei, in particular, has explicitly compared the development of AI to "The Making of the Atomic Bomb," emphasizing the weighty decisions involved.

## The So What?
This high-stakes saga, described as "truly an insane series of events" by the hosts, reveals a fundamental debate over who controls powerful AI technologies and how they will ultimately be used. It underscores the urgent need for clear AI regulation and robust privacy laws in the U.S., as current ambiguities risk ushering in new systems of potential oppression under the guise of "all lawful use." The full implications for the AI industry's relationship with national security remain uncertain, with some predicting a "chilling effect" across Silicon Valley.
